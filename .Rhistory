source("C:/Users/PC-DESKTOP_CARLOS/OneDrive/nivel 7 - 2°semestre 2021/IME - Inferencia y modelos estadísticos/Unidad2/EP08-Enunciado/EP08-respuesta-sala-4.R")
source("C:/Users/PC-DESKTOP_CARLOS/OneDrive/nivel 7 - 2°semestre 2021/IME - Inferencia y modelos estadísticos/Unidad2/EP09-Enunciado/EP09-respuesta-sala-4.R")
source("C:/Users/PC-DESKTOP_CARLOS/OneDrive/nivel 7 - 2°semestre 2021/IME - Inferencia y modelos estadísticos/Unidad2/EP10-Enunciado/EP10-respuesta-sala-4.R")
texto <-("
Dataset C2 Dataset C4
'tae' 43.82 'credit' 85.67
'anneal' 97.44 'monks' 61.68
'pasture-production' 85.27 'soybean' 91.52
'contact-lenses' 67.77 'segment' 90.74
'primary-tumor' 47.52 'squash-unstored' 61.11
'kr-s-kp' 91.90 'mushroom' 95.27
'solar-flare-C' 87.68 'page-blocks' 92.95
'monks1' 99.44 'grub-damage' 47.23
'white-clover' 78.73 'cmc' 50.49
'ecoli' 79.48 'waveform' 79.30
'nursery' 93.72 'postoperatie' 66.11
'squash-stored' 57.44 -- --
")
datos <- read.table(textConnection(texto), header = TRUE, na.strings = "--")
#-------------------------------------------------------------------------------
# Respuesta:
cat("\n----------------------------------------------------------------------")
cat("\n                            PREGUNTA 1")
cat("\n----------------------------------------------------------------------\n")
# Histograma del algoritmo Bayes ingenuo oculto (C2)
g1 <- gghistogram ( datos ,
x = "C2",
bins = 10,
add = "mean",
xlab = "Porcentaje de acierto",
ylab = "Frecuencia",
title = "Histograma del algoritmo C2",
color = "black",
fill = "blue")
print(g1)
# Histograma del algoritmo Bayes ingenuo (C4)
g2 <- gghistogram ( datos ,
x = "C4",
bins = 10,
add = "mean",
xlab = "Porcentaje de acierto",
ylab = "Frecuencia",
title = "Histograma del algoritmo C4",
color = "black",
fill = "blue")
print(g2)
alfa <- 0.01
prueba <- wilcox.test(datos$C2 ,
datos$C4 ,
alternative = "two.sided",
conf.level = 1 - alfa )
cat("\nPrueba de suma de rangos de Wilcoxon mediante wilcox.test:\n")
print ( prueba )
# Entonces, de acuerdo a los resultados, el valor de p obtenido es 0.6947,
# Entonces, de acuerdo a los resultados, el valor de p obtenido es 0.6947,
# siendo demasiado alto para el nivel de significancia definido (alfa = 0.01),
# Entonces, de acuerdo a los resultados, el valor de p obtenido es 0.6947,
# siendo demasiado alto para el nivel de significancia definido (alfa = 0.01),
# por lo que se falla al rechazar la hipótesis nula a favor de la alternativa.
# Entonces, de acuerdo a los resultados, el valor de p obtenido es 0.6947,
# siendo demasiado alto para el nivel de significancia definido (alfa = 0.01),
# por lo que se falla al rechazar la hipótesis nula a favor de la alternativa.
# Por lo tanto, con un 99% de confianza, se concluye que no existe diferencia
# Entonces, de acuerdo a los resultados, el valor de p obtenido es 0.6947,
# siendo demasiado alto para el nivel de significancia definido (alfa = 0.01),
# por lo que se falla al rechazar la hipótesis nula a favor de la alternativa.
# Por lo tanto, con un 99% de confianza, se concluye que no existe diferencia
# en el porcentaje de acierto en ambos algoritmos, por lo que ningún algoritmo
